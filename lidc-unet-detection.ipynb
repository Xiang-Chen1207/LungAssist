{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T21:35:49.246976Z",
     "iopub.status.idle": "2024-03-14T21:35:49.24766Z",
     "shell.execute_reply": "2024-03-14T21:35:49.247382Z",
     "shell.execute_reply.started": "2024-03-14T21:35:49.247352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf # Imports tensorflow\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Embedding,TimeDistributed\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ReLU, LSTM,Bidirectional,Attention,Concatenate,concatenate\n",
    "from tensorflow.keras import regularizers, optimizers,losses\n",
    "from tensorflow.keras.layers import DepthwiseConv2D,Add, ReLU, GlobalAveragePooling2D, GlobalMaxPooling2D,MultiHeadAttention\n",
    "from tensorflow.keras.layers import Activation,ActivityRegularization, AvgPool2D, LeakyReLU, Conv2DTranspose\n",
    "from tensorflow.keras.metrics import Accuracy,Recall,Precision,AUC,TruePositives,TrueNegatives,FalseNegatives,FalsePositives, SpecificityAtSensitivity,SensitivityAtSpecificity\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "#import imblearn\n",
    "#from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sklearn.metrics as m\n",
    "from glob import glob\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.listdir('/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T16:27:28.916986Z",
     "iopub.status.busy": "2023-11-01T16:27:28.916353Z",
     "iopub.status.idle": "2023-11-01T16:27:32.515725Z",
     "shell.execute_reply": "2023-11-01T16:27:32.514651Z",
     "shell.execute_reply.started": "2023-11-01T16:27:28.916955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/kaggle/working/CnnRegulized.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **Testing The data and Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T16:29:29.632598Z",
     "iopub.status.busy": "2023-11-23T16:29:29.632043Z",
     "iopub.status.idle": "2023-11-23T16:29:29.638201Z",
     "shell.execute_reply": "2023-11-23T16:29:29.636865Z",
     "shell.execute_reply.started": "2023-11-23T16:29:29.63257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images=[]\n",
    "masks=[]\n",
    "y=[]\n",
    "gr_shape=(128,128,1)\n",
    "img_shape = (128,128,3)\n",
    "input_dir=\"/home/chenx/code/medical_project/data/LIDC-IDRI-slices\"\n",
    "out_dir = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-21T18:34:29.656377Z",
     "iopub.status.busy": "2023-09-21T18:34:29.655872Z",
     "iopub.status.idle": "2023-09-21T18:34:30.006087Z",
     "shell.execute_reply": "2023-09-21T18:34:30.004682Z",
     "shell.execute_reply.started": "2023-09-21T18:34:29.656332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img=image.load_img('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0004/nodule-0/images/slice-1.png')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T18:52:26.479618Z",
     "iopub.status.idle": "2023-08-16T18:52:26.480508Z",
     "shell.execute_reply": "2023-08-16T18:52:26.48025Z",
     "shell.execute_reply.started": "2023-08-16T18:52:26.480224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.asarray(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T18:52:26.482058Z",
     "iopub.status.idle": "2023-08-16T18:52:26.482961Z",
     "shell.execute_reply": "2023-08-16T18:52:26.482712Z",
     "shell.execute_reply.started": "2023-08-16T18:52:26.482686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.array(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T18:52:26.484428Z",
     "iopub.status.idle": "2023-08-16T18:52:26.485286Z",
     "shell.execute_reply": "2023-08-16T18:52:26.485046Z",
     "shell.execute_reply.started": "2023-08-16T18:52:26.485021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.array(masks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T11:59:25.387594Z",
     "iopub.status.busy": "2023-11-04T11:59:25.385829Z",
     "iopub.status.idle": "2023-11-04T11:59:25.896468Z",
     "shell.execute_reply": "2023-11-04T11:59:25.895234Z",
     "shell.execute_reply.started": "2023-11-04T11:59:25.387555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images=[]\n",
    "\n",
    "y=[]\n",
    "for nodule in os.listdir('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0001'):\n",
    "        mask0=[]\n",
    "        mask1=[]\n",
    "        mask2=[]\n",
    "        mask3=[]\n",
    "        for filename in glob('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0001/'+nodule+'/images/*.png'):\n",
    "            print(filename)\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            images.append(img)\n",
    "        for filename in glob('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0001/'+nodule+'/mask-0/*.png'):\n",
    "            print(filename)\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask0.append(img)\n",
    "        for filename in glob('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0001/'+nodule+'/mask-1/*.png'):\n",
    "            print(filename)\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask1.append(img)\n",
    "        for filename in glob('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0001/'+nodule+'/mask-2/*.png'):\n",
    "            print(filename)\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask2.append(img)\n",
    "        for filename in glob('/home/chenx/code/medical_project/data/LIDC-IDRI-slices/LIDC-IDRI-0001/'+nodule+'/mask-3/*.png'):\n",
    "            print(filename)\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask3.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T18:52:26.48923Z",
     "iopub.status.idle": "2023-08-16T18:52:26.490058Z",
     "shell.execute_reply": "2023-08-16T18:52:26.489834Z",
     "shell.execute_reply.started": "2023-08-16T18:52:26.489809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "i=7\n",
    "print(mask0[i].sum())\n",
    "print(mask1[i].sum())\n",
    "print(mask2[i].sum())\n",
    "print(mask3[i].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-16T18:52:26.522923Z",
     "iopub.status.busy": "2023-08-16T18:52:26.521961Z",
     "iopub.status.idle": "2023-08-16T18:52:26.555455Z",
     "shell.execute_reply": "2023-08-16T18:52:26.553711Z",
     "shell.execute_reply.started": "2023-08-16T18:52:26.522886Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask0[i])\n",
    "plt.show()\n",
    "plt.imshow(mask1[i])\n",
    "plt.show()\n",
    "plt.imshow(mask2[i])\n",
    "plt.show()\n",
    "plt.imshow(mask3[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-16T18:52:26.556513Z",
     "iopub.status.idle": "2023-08-16T18:52:26.557374Z",
     "shell.execute_reply": "2023-08-16T18:52:26.557123Z",
     "shell.execute_reply.started": "2023-08-16T18:52:26.557087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Thres = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T06:58:25.47909Z",
     "iopub.status.busy": "2023-05-06T06:58:25.478712Z",
     "iopub.status.idle": "2023-05-06T06:58:25.490098Z",
     "shell.execute_reply": "2023-05-06T06:58:25.489246Z",
     "shell.execute_reply.started": "2023-05-06T06:58:25.479058Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gmask=[]\n",
    "for i in range(len(mask0)):\n",
    "    white_sum=np.array([mask0[i].sum(),mask1[i].sum(),mask2[i].sum(),mask3[i].sum()])\n",
    "    cnt=int(mask0[i].sum()>Thres)+int(mask1[i].sum()>Thres)+int(mask2[i].sum()>Thres)+int(mask3[i].sum()>Thres)\n",
    "    print(cnt)\n",
    "    if(cnt>2):\n",
    "        print(\"ID =\"+str(white_sum.argmax()))\n",
    "        print(white_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **Run From Here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T14:30:00.386542Z",
     "iopub.status.busy": "2023-11-27T14:30:00.386119Z",
     "iopub.status.idle": "2023-11-27T14:30:00.392485Z",
     "shell.execute_reply": "2023-11-27T14:30:00.391665Z",
     "shell.execute_reply.started": "2023-11-27T14:30:00.386508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gr_shape=(128,128,1)\n",
    "img_shape = (128,128,3)\n",
    "input_dir=\"/home/chenx/code/medical_project/data/LIDC-IDRI-slices\"\n",
    "images=[]\n",
    "masks=[]\n",
    "y=[]\n",
    "Thres = 5000/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T14:30:05.118408Z",
     "iopub.status.busy": "2023-11-27T14:30:05.117624Z",
     "iopub.status.idle": "2023-11-27T14:34:14.311946Z",
     "shell.execute_reply": "2023-11-27T14:34:14.310833Z",
     "shell.execute_reply.started": "2023-11-27T14:30:05.118371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for patient in os.listdir(input_dir):\n",
    "    if len(images)>10000:\n",
    "        break\n",
    "    for nodule in os.listdir(input_dir+'/'+patient):\n",
    "        mask0=[]\n",
    "        mask1=[]\n",
    "        mask2=[]\n",
    "        mask3=[]\n",
    "        for filename in glob(input_dir+'/'+patient+'/'+nodule+'/images/*.png'):\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            images.append(img)\n",
    "        for filename in glob(input_dir+'/'+patient+'/'+nodule+'/mask-0/*.png'):\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask0.append(img)\n",
    "        for filename in glob(input_dir+'/'+patient+'/'+nodule+'/mask-1/*.png'):\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask1.append(img)\n",
    "        for filename in glob(input_dir+'/'+patient+'/'+nodule+'/mask-2/*.png'):\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask2.append(img)\n",
    "        for filename in glob(input_dir+'/'+patient+'/'+nodule+'/mask-3/*.png'):\n",
    "            img = image.load_img(filename,target_size=img_shape)\n",
    "            img = np.asarray(img)\n",
    "            mask3.append(img)\n",
    "        for i in range(len(mask0)):\n",
    "            white_sum=np.array([mask0[i].sum(),mask1[i].sum(),mask2[i].sum(),mask3[i].sum()])\n",
    "            cnt=int(mask0[i].sum()>Thres)+int(mask1[i].sum()>Thres)+int(mask2[i].sum()>Thres)+int(mask3[i].sum()>Thres)\n",
    "            if(cnt>2):\n",
    "                y.append(1)\n",
    "                if white_sum.argmax()==0:\n",
    "                    masks.append(mask0[i])\n",
    "                elif white_sum.argmax()==1:\n",
    "                    masks.append(mask1[i])\n",
    "                elif white_sum.argmax()==2:\n",
    "                    masks.append(mask2[i])\n",
    "                else:\n",
    "                    masks.append(mask3[i])\n",
    "            else:\n",
    "                y.append(0)\n",
    "                if white_sum.argmin()==0:\n",
    "                    masks.append(mask0[i])\n",
    "                elif white_sum.argmin()==1:\n",
    "                    masks.append(mask1[i])\n",
    "                elif white_sum.argmin()==2:\n",
    "                    masks.append(mask2[i])\n",
    "                else:\n",
    "                    masks.append(mask3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T14:41:13.150579Z",
     "iopub.status.busy": "2023-11-27T14:41:13.150093Z",
     "iopub.status.idle": "2023-11-27T14:41:17.301438Z",
     "shell.execute_reply": "2023-11-27T14:41:17.300545Z",
     "shell.execute_reply.started": "2023-11-27T14:41:13.150528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images=np.array(images)/255\n",
    "masks=np.array(masks)/255\n",
    "label=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UNET ei porjonto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T14:41:17.303479Z",
     "iopub.status.busy": "2023-11-27T14:41:17.303126Z",
     "iopub.status.idle": "2023-11-27T14:41:17.309368Z",
     "shell.execute_reply": "2023-11-27T14:41:17.308425Z",
     "shell.execute_reply.started": "2023-11-27T14:41:17.303449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(masks.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:18:08.281297Z",
     "iopub.status.busy": "2023-11-23T18:18:08.281017Z",
     "iopub.status.idle": "2023-11-23T18:18:08.300595Z",
     "shell.execute_reply": "2023-11-23T18:18:08.29968Z",
     "shell.execute_reply.started": "2023-11-23T18:18:08.281274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "yy=pd.DataFrame(label)\n",
    "yy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T14:41:25.467976Z",
     "iopub.status.busy": "2023-11-27T14:41:25.467604Z",
     "iopub.status.idle": "2023-11-27T14:41:28.684812Z",
     "shell.execute_reply": "2023-11-27T14:41:28.683658Z",
     "shell.execute_reply.started": "2023-11-27T14:41:25.467949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,mask_train,mask_test = train_test_split(images,label,masks,train_size=0.8, random_state=7)\n",
    "print(x_train.shape)\n",
    "print(mask_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T20:27:36.707418Z",
     "iopub.status.busy": "2023-11-17T20:27:36.706468Z",
     "iopub.status.idle": "2023-11-17T20:27:37.265049Z",
     "shell.execute_reply": "2023-11-17T20:27:37.264067Z",
     "shell.execute_reply.started": "2023-11-17T20:27:36.70738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images = np.nan_to_num(images)\n",
    "masks = np.nan_to_num(masks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T21:02:22.414388Z",
     "iopub.status.busy": "2023-11-17T21:02:22.414052Z",
     "iopub.status.idle": "2023-11-17T21:02:22.943328Z",
     "shell.execute_reply": "2023-11-17T21:02:22.942244Z",
     "shell.execute_reply.started": "2023-11-17T21:02:22.41436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.isnan(masks).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T20:14:58.534226Z",
     "iopub.status.busy": "2023-11-17T20:14:58.533531Z",
     "iopub.status.idle": "2023-11-17T20:14:58.53956Z",
     "shell.execute_reply": "2023-11-17T20:14:58.538737Z",
     "shell.execute_reply.started": "2023-11-17T20:14:58.534195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:10:25.271737Z",
     "iopub.status.busy": "2023-11-04T12:10:25.271364Z",
     "iopub.status.idle": "2023-11-04T12:10:25.54993Z",
     "shell.execute_reply": "2023-11-04T12:10:25.549071Z",
     "shell.execute_reply.started": "2023-11-04T12:10:25.271704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train_added = np.vstack([x_train,x_test[:2000]])\n",
    "y_train_added = np.concatenate((y_train,y_test[:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T20:18:28.928111Z",
     "iopub.status.busy": "2023-11-17T20:18:28.927054Z",
     "iopub.status.idle": "2023-11-17T20:18:28.932893Z",
     "shell.execute_reply": "2023-11-17T20:18:28.931922Z",
     "shell.execute_reply.started": "2023-11-17T20:18:28.928066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(mask_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNET Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **UNET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:18:14.646254Z",
     "iopub.status.busy": "2023-11-23T18:18:14.645889Z",
     "iopub.status.idle": "2023-11-23T18:18:14.668699Z",
     "shell.execute_reply": "2023-11-23T18:18:14.667884Z",
     "shell.execute_reply.started": "2023-11-23T18:18:14.646226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name='lidcUnet0'\n",
    "def segment_model():\n",
    "    inputs = keras.Input(shape=img_shape, name=\"img\")\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    down1 = MaxPooling2D((2, 2)) (c1)\n",
    "    \n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (down1)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Dropout(0.2) (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    \n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Dropout(0.2) (c3)    \n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    \n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    \n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    \n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    \n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    \n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    \n",
    "    u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    \n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid') (c9)\n",
    "    model = keras.Model(inputs, outputs, name=Name)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), \n",
    "                  loss='binary_crossentropy', metrics=['accuracy',Recall(),Precision(),AUC()])\n",
    "    model.summary()\n",
    "    plot_model(model, to_file=Name+'seg.png',show_shapes= True , show_layer_names=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T18:18:17.542385Z",
     "iopub.status.busy": "2023-11-23T18:18:17.541606Z",
     "iopub.status.idle": "2023-11-23T18:18:18.529548Z",
     "shell.execute_reply": "2023-11-23T18:18:18.528758Z",
     "shell.execute_reply.started": "2023-11-23T18:18:17.542351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = segment_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-23T18:18:23.351443Z",
     "iopub.status.busy": "2023-11-23T18:18:23.350641Z",
     "iopub.status.idle": "2023-11-23T20:34:43.701582Z",
     "shell.execute_reply": "2023-11-23T20:34:43.700564Z",
     "shell.execute_reply.started": "2023-11-23T18:18:23.351409Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "earlystopper = EarlyStopping(patience=100, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_unet_checkpoint.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(x_train,mask_train, validation_data=(x_test,mask_test), batch_size=32, epochs=300, \n",
    "                   )\n",
    "# callbacks=[earlystopper, checkpointer]\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(results.history).to_csv(Name+'new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T22:01:55.088976Z",
     "iopub.status.busy": "2023-11-23T22:01:55.088337Z",
     "iopub.status.idle": "2023-11-23T22:02:06.407892Z",
     "shell.execute_reply": "2023-11-23T22:02:06.407027Z",
     "shell.execute_reply.started": "2023-11-23T22:01:55.088941Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_impr= model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T22:00:06.984197Z",
     "iopub.status.busy": "2023-11-23T22:00:06.983831Z",
     "iopub.status.idle": "2023-11-23T22:00:07.296183Z",
     "shell.execute_reply": "2023-11-23T22:00:07.291096Z",
     "shell.execute_reply.started": "2023-11-23T22:00:06.984168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img_id=1019\n",
    "new_img= np.array(x_train[img_id])\n",
    "plt.imshow(x_train[img_id])\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.imshow(mask_train[img_id])\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "new_img = new_img.reshape(1,128,128,3)\n",
    "new_impr= model.predict(new_img)\n",
    "plt.imshow(new_impr[0])\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"Activation_Layer5D7\"+'.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T22:27:17.114331Z",
     "iopub.status.busy": "2023-11-23T22:27:17.113624Z",
     "iopub.status.idle": "2023-11-23T22:27:17.530977Z",
     "shell.execute_reply": "2023-11-23T22:27:17.5298Z",
     "shell.execute_reply.started": "2023-11-23T22:27:17.114302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img_id=1789\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "a = fig.add_subplot(3, 1, 1)\n",
    "plt.imshow(x_train[img_id])\n",
    "#a.set_title(\"original\",fontsize=10)\n",
    "plt.axis('off')\n",
    "a = fig.add_subplot(3, 1, 2)\n",
    "plt.imshow(mask_train[img_id])\n",
    "#a.set_title(\"True Mask\",fontsize=10)\n",
    "plt.axis('off')\n",
    "a = fig.add_subplot(3, 1, 3)\n",
    "plt.imshow(new_impr[img_id],interpolation='nearest')\n",
    "#a.set_title(\"Predicted\",fontsize=10)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Segmentation\"+str(img_id)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T22:29:19.911922Z",
     "iopub.status.busy": "2023-11-23T22:29:19.911026Z",
     "iopub.status.idle": "2023-11-23T22:29:22.477192Z",
     "shell.execute_reply": "2023-11-23T22:29:22.476377Z",
     "shell.execute_reply.started": "2023-11-23T22:29:19.911876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_mask_test= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T22:37:47.113739Z",
     "iopub.status.busy": "2023-11-23T22:37:47.113289Z",
     "iopub.status.idle": "2023-11-23T22:37:47.123175Z",
     "shell.execute_reply": "2023-11-23T22:37:47.122297Z",
     "shell.execute_reply.started": "2023-11-23T22:37:47.113705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from skimage.metrics import adapted_rand_error as ARE\n",
    "from skimage.metrics import hausdorff_distance as HD\n",
    "from skimage.metrics import mean_squared_error as MSE\n",
    "from skimage.metrics import normalized_root_mse as Nrmse\n",
    "from skimage.metrics import normalized_mutual_information as NMI\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import variation_of_information as VOI\n",
    "smooth=1.0\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    sum_ = np.sum(y_true + y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac\n",
    "\n",
    "result= [['CV','PSNR', 'BCE-DL', 'IOU', 'DC', 'MSE','SSIM','NRMSE','Normalized_Mutual_information']]\n",
    "for each mask_test2 in bw_imgs: \n",
    "        v_PSNR = PSNR(mask_test2,pred_mask_test)\n",
    "        v_bce_dl = bce_dice_loss(mask_test2,pred_mask_test)\n",
    "        v_dc = dice_coef(mask_test2,pred_mask_test)\n",
    "        v_dl = dice_coef_loss(mask_test2,pred_mask_test)\n",
    "        v_iou = iou(mask_test2,pred_mask_test)\n",
    "        v_ssim = SSIM(mask_test2,pred_mask_test,data_range=1, channel_axis=3)\n",
    "        #v_are = ARE(mask_test,pred_mask_test)\n",
    "        #v_hd = HD(mask_test,pred_mask_test)\n",
    "        v_mse = MSE(mask_test2,pred_mask_test)\n",
    "        v_nrmse = Nrmse(mask_test2,pred_mask_test)\n",
    "        v_nmi = NMI(mask_test2,pred_mask_test)\n",
    "        #v_voi = VOI(mask_test,pred_mask_test)\n",
    "        result.append([v_PSNR ,v_bce_dl.numpy(), v_iou ,v_dc ,v_mse,v_ssim,v_nrmse,v_nmi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:33:51.893459Z",
     "iopub.status.busy": "2023-11-23T23:33:51.892735Z",
     "iopub.status.idle": "2023-11-23T23:33:51.897801Z",
     "shell.execute_reply": "2023-11-23T23:33:51.896896Z",
     "shell.execute_reply.started": "2023-11-23T23:33:51.893427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result= [['CV','PSNR', 'BCE-DL', 'IOU', 'DC', 'MSE','SSIM','NRMSE','Normalized_Mutual_information']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:44:48.61914Z",
     "iopub.status.busy": "2023-11-23T23:44:48.618454Z",
     "iopub.status.idle": "2023-11-23T23:45:22.491321Z",
     "shell.execute_reply": "2023-11-23T23:45:22.490475Z",
     "shell.execute_reply.started": "2023-11-23T23:44:48.619107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "v_PSNR = PSNR(mask_test2,pred_mask_test)\n",
    "v_bce_dl = bce_dice_loss(mask_test2,pred_mask_test)\n",
    "v_dc = dice_coef(mask_test2,pred_mask_test)\n",
    "v_dl = dice_coef_loss(mask_test2,pred_mask_test)\n",
    "v_iou = iou(mask_test2,pred_mask_test)\n",
    "v_ssim = SSIM(mask_test2,pred_mask_test,data_range=1, channel_axis=3)\n",
    "#v_are = ARE(mask_test,pred_mask_test)\n",
    "#v_hd = HD(mask_test,pred_mask_test)\n",
    "v_mse = MSE(mask_test2,pred_mask_test)\n",
    "v_nrmse = Nrmse(mask_test2,pred_mask_test)\n",
    "v_nmi = NMI(mask_test2,pred_mask_test)\n",
    "#v_voi = VOI(mask_test,pred_mask_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:39:04.895181Z",
     "iopub.status.busy": "2023-11-23T23:39:04.894853Z",
     "iopub.status.idle": "2023-11-23T23:39:04.901463Z",
     "shell.execute_reply": "2023-11-23T23:39:04.900566Z",
     "shell.execute_reply.started": "2023-11-23T23:39:04.895155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:44:31.972756Z",
     "iopub.status.busy": "2023-11-23T23:44:31.97207Z",
     "iopub.status.idle": "2023-11-23T23:44:34.475383Z",
     "shell.execute_reply": "2023-11-23T23:44:34.474497Z",
     "shell.execute_reply.started": "2023-11-23T23:44:31.972721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_mask_test= model.predict(x_train[:2002])\n",
    "mask_test2= mask_train[:2002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:45:22.493195Z",
     "iopub.status.busy": "2023-11-23T23:45:22.49291Z",
     "iopub.status.idle": "2023-11-23T23:45:22.498296Z",
     "shell.execute_reply": "2023-11-23T23:45:22.497314Z",
     "shell.execute_reply.started": "2023-11-23T23:45:22.493171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "result.append(['5th',v_PSNR ,v_bce_dl.numpy(), v_iou ,v_dc ,v_mse,v_ssim,v_nrmse,v_nmi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:45:22.499565Z",
     "iopub.status.busy": "2023-11-23T23:45:22.499275Z",
     "iopub.status.idle": "2023-11-23T23:45:22.515708Z",
     "shell.execute_reply": "2023-11-23T23:45:22.514517Z",
     "shell.execute_reply.started": "2023-11-23T23:45:22.499533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-23T23:45:22.518257Z",
     "iopub.status.busy": "2023-11-23T23:45:22.517807Z",
     "iopub.status.idle": "2023-11-23T23:45:22.529242Z",
     "shell.execute_reply": "2023-11-23T23:45:22.528489Z",
     "shell.execute_reply.started": "2023-11-23T23:45:22.518223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(result).to_csv('Cross_val_UNET.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Skip from here for transfer learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T20:39:11.326933Z",
     "iopub.status.busy": "2023-08-04T20:39:11.326317Z",
     "iopub.status.idle": "2023-08-04T20:39:11.528099Z",
     "shell.execute_reply": "2023-08-04T20:39:11.527093Z",
     "shell.execute_reply.started": "2023-08-04T20:39:11.326898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T20:39:13.778087Z",
     "iopub.status.busy": "2023-08-04T20:39:13.777736Z",
     "iopub.status.idle": "2023-08-04T20:39:13.965051Z",
     "shell.execute_reply": "2023-08-04T20:39:13.96344Z",
     "shell.execute_reply.started": "2023-08-04T20:39:13.77806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T20:39:17.795009Z",
     "iopub.status.busy": "2023-08-04T20:39:17.794602Z",
     "iopub.status.idle": "2023-08-04T20:39:17.978679Z",
     "shell.execute_reply": "2023-08-04T20:39:17.977759Z",
     "shell.execute_reply.started": "2023-08-04T20:39:17.794981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0]*masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def block(inp,filters):\n",
    "    x = Conv2D(filters, 1, activation=\"relu\",padding='same',kernel_initializer='he_normal')(inp)\n",
    "    x = BatchNormalization(axis=1)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    y = Conv2D(filters,1,activation=\"relu\", padding='same',kernel_initializer='he_normal')(inp)\n",
    "    y = Conv2D(filters*2,3,activation=\"relu\", padding='same')(y)\n",
    "    y = Conv2D(filters,3,activation=\"relu\", padding='same')(y)\n",
    "    y = BatchNormalization(axis=1)(y)\n",
    "    y = Dropout(0.25)(y)\n",
    "    \n",
    "    z = Conv2D(filters, 1, activation=\"relu\", padding='same',kernel_initializer='he_normal')(inp)\n",
    "    z = Conv2D(filters, 3, activation=\"relu\", padding='same')(inp)\n",
    "    z = BatchNormalization(axis=1)(z)\n",
    "    \n",
    "# outconv = Conv2D(filters, 1, activation=\"relu\", padding='same',kernel_initializer='he_normal')([x,y,z,inp])\n",
    "    outcon = layers.Concatenate()([x,y,z,inp])\n",
    "    outconv = Conv2D(filters*2, 1, activation=\"relu\", padding='same',kernel_initializer='he_normal')(outcon)\n",
    "    output = MaxPooling2D(pool_size=(2,2))(outconv)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T17:44:13.844489Z",
     "iopub.status.busy": "2023-08-23T17:44:13.843854Z",
     "iopub.status.idle": "2023-08-23T17:44:17.09647Z",
     "shell.execute_reply": "2023-08-23T17:44:17.095607Z",
     "shell.execute_reply.started": "2023-08-23T17:44:13.84445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name = \"CnnRegulized\"\n",
    "inputs = keras.Input(shape=img_shape, name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "#x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "y = block(x,32)\n",
    "y = block(y,64)\n",
    "y = block(y,128)\n",
    "#y = layers.Conv2D(256, 3, activation=\"relu\")(y)\n",
    "# y = Conv2D(filters=64, kernel_size=(5, 5), activation='relu')(x)\n",
    "# y = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(y)\n",
    "# y = MaxPooling2D((2,2))(y)\n",
    "# y = BatchNormalization(axis=-1)(y)\n",
    "# y = Dropout(0.25)(y)\n",
    "# y = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(y)\n",
    "# y = MaxPooling2D((2,2))(y)\n",
    "# y = BatchNormalization(axis=-1)(y)\n",
    "# y = Dropout(0.25)(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(128, activation=\"LeakyReLU\", kernel_regularizer=regularizers.l2(0.02))(y)\n",
    "#y = BatchNormalization()(y)\n",
    "y = Dropout(0.25)(y)\n",
    "y = Dense(64, activation='LeakyReLU',kernel_regularizer=regularizers.l2(0.02))(y) #sigmoid activation\n",
    "y = Dropout(0.25)(y)\n",
    "outputs=Dense(1, activation='sigmoid')(y)\n",
    "model = keras.Model(inputs, outputs, name=Name)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T19:38:53.439229Z",
     "iopub.status.busy": "2023-08-16T19:38:53.438656Z",
     "iopub.status.idle": "2023-08-16T19:38:53.631754Z",
     "shell.execute_reply": "2023-08-16T19:38:53.630981Z",
     "shell.execute_reply.started": "2023-08-16T19:38:53.439166Z"
    }
   },
   "source": [
    "## Name = \"Seq3cnn\"\n",
    "inputs = keras.Input(shape=img_shape, name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "#x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "# y = block(x,64)\n",
    "# y = block(y,128)\n",
    "# y = block(y,256)\n",
    "#y = layers.Conv2D(256, 3, activation=\"relu\")(y)\n",
    "y = Conv2D(filters=128, kernel_size=(5, 5), activation='relu')(x)\n",
    "y = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(y)\n",
    "y = MaxPooling2D((2,2))(y)\n",
    "y = BatchNormalization(axis=-1)(y)\n",
    "y = Dropout(0.25)(y)\n",
    "y = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(y)\n",
    "y = MaxPooling2D((2,2))(y)\n",
    "y = BatchNormalization(axis=-1)(y)\n",
    "y = Dropout(0.25)(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(128, activation=\"LeakyReLU\", kernel_regularizer=regularizers.l2(0.001))(y)\n",
    "y = Dropout(0.25)(y)\n",
    "y = Dense(32, activation='sigmoid',kernel_regularizer=regularizers.l2(0.001))(y)\n",
    "y = Dropout(0.25)(y)\n",
    "outputs=Dense(1, activation='sigmoid')(y)\n",
    "model = keras.Model(inputs, outputs, name=Name)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:29:50.476148Z",
     "iopub.status.busy": "2023-08-16T22:29:50.475789Z",
     "iopub.status.idle": "2023-08-16T22:29:50.79857Z",
     "shell.execute_reply": "2023-08-16T22:29:50.797683Z",
     "shell.execute_reply.started": "2023-08-16T22:29:50.47612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='modelfinal.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T17:44:17.098032Z",
     "iopub.status.busy": "2023-08-23T17:44:17.097639Z",
     "iopub.status.idle": "2023-08-23T18:16:49.053744Z",
     "shell.execute_reply": "2023-08-23T18:16:49.052545Z",
     "shell.execute_reply.started": "2023-08-23T17:44:17.097976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "history = model.fit(x_train_added, y_train_added, epochs=100, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:49:11.05557Z",
     "iopub.status.busy": "2023-08-16T22:49:11.054733Z",
     "iopub.status.idle": "2023-08-16T23:18:39.781457Z",
     "shell.execute_reply": "2023-08-16T23:18:39.779983Z",
     "shell.execute_reply.started": "2023-08-16T22:49:11.055526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "history = model.fit(x_train_added, y_train_added, epochs=100, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BiLSTM- Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "class attention(Layer):\n",
    "    \n",
    "    \"\"\"This class implents the attention mechanism layer: We will define a class named Attention as a derived class of the Layer class. We need to define four functions as per the Keras custom layer generation rule. \n",
    "    These are build(),call (), compute_output_shape() and get_config().\"\"\"\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    \"\"\"Inside build (), we will define our weights and biases, i.e., Wa and B . \n",
    "    If the previous LSTM layer’s output shape is (None, 32, 100)\n",
    "    then our output weight should be (100, 1) and bias should be (100, 1) dimensional.\"\"\"\n",
    "    def build(self,input_shape):\n",
    "        self.w=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")\n",
    "        super(attention,self).build(input_shape)\n",
    "        \n",
    "        \n",
    "    \"\"\"Inside call (), we will write the main logic of Attention. We simply must create a Multi-Layer Perceptron (MLP). \n",
    "    Therefore, we will take the dot product of weights and inputs followed by the addition of bias terms. \n",
    "    After that, we apply a ‘tanh’ followed by a softmax layer. This softmax gives the alignment scores. \n",
    "    Its dimension will be the number of hidden states in the LSTM, i.e., 32 in this case. \n",
    "    Taking its dot product along with the hidden states will provide the context vector:\"\"\"    \n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.w)+self.b), axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "    \"The get_config() method collects the input shape and other information about the model.\"\"\"\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, Conv2DTranspose, Attention, Layer, Reshape\n",
    "\n",
    "class VisualAttention(Layer):\n",
    "    def __init__(self, channels_out, key_is_value=True):\n",
    "        super(VisualAttention, self).__init__()\n",
    "\n",
    "        self.channels_out = channels_out\n",
    "        self.key_is_value = key_is_value\n",
    "\n",
    "        self.flatten_images = None  # see build method\n",
    "        self.unflatten_images = None  # see build method\n",
    "\n",
    "        self.query_conv = Conv1D(filters=channels_out, kernel_size=1, padding='same')\n",
    "        self.value_conv = Conv1D(filters=channels_out, kernel_size=4, padding='same')\n",
    "        self.key_conv = self.value_conv if key_is_value else Conv1D(filters=channels_out, kernel_size=4, padding='same')\n",
    "\n",
    "        self.attention_layer = Attention(use_scale=False, causal=False, dropout=0.)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        b, h, w, c = input_shape\n",
    "        self.flatten_images = Reshape((h*w, c), input_shape=(h, w, c))\n",
    "        self.unflatten_images = Reshape((h, w, self.channels_out), input_shape=(h*w, self.channels_out))\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = self.flatten_images(x)\n",
    "        q = self.query_conv(x)\n",
    "        v = self.value_conv(x)\n",
    "\n",
    "        inputs = [q, v] if self.key_is_value else [q, v, self.key_conv(x)]\n",
    "        output = self.attention_layer(inputs=inputs, training=training)\n",
    "        return self.unflatten_images(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T18:25:52.023585Z",
     "iopub.status.busy": "2023-08-23T18:25:52.023195Z",
     "iopub.status.idle": "2023-08-23T18:25:52.175601Z",
     "shell.execute_reply": "2023-08-23T18:25:52.174558Z",
     "shell.execute_reply.started": "2023-08-23T18:25:52.023548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = VisualAttention(8)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T18:33:31.300133Z",
     "iopub.status.busy": "2023-08-23T18:33:31.299707Z",
     "iopub.status.idle": "2023-08-23T18:33:31.54734Z",
     "shell.execute_reply": "2023-08-23T18:33:31.546422Z",
     "shell.execute_reply.started": "2023-08-23T18:33:31.300099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name = \"CNNVisAttention\"\n",
    "inputs = tf.keras.Input(shape=img_shape, name=\"img\")\n",
    "#converted = tf.image.rgb_to_grayscale(inputs)\n",
    "#reshaped_input = layers.Reshape((128,128))(converted)\n",
    "x = layers.Conv2D(8, 3, activation=\"relu\")(inputs)\n",
    "#x = VisualAttention(8)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(16,(3,3),activation='relu')(x)\n",
    "x = VisualAttention(16)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(32,(3,3),activation='relu')(x)\n",
    "x = VisualAttention(32)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "y = Flatten()(x)\n",
    "# x1 = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))(reshaped_input)\n",
    "# x1 = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))(x1)\n",
    "# atte_layer=attention()(x1)\n",
    "#outputs=Dense(1,activation='sigmoid',trainable=True)(atte_layer)\n",
    "\n",
    "# y = Dense(128, activation=\"LeakyReLU\", kernel_regularizer=regularizers.l2(0.01))(x1)\n",
    "# y = Dropout(0.25)(y)\n",
    "y = Dense(64, activation='LeakyReLU',kernel_regularizer=regularizers.l2(0.01))(y)\n",
    "y = Dropout(0.25)(y)\n",
    "outputs=Dense(1, activation='sigmoid')(y)\n",
    "model = keras.Model(inputs, outputs, name=Name)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-23T18:33:37.111117Z",
     "iopub.status.busy": "2023-08-23T18:33:37.110709Z",
     "iopub.status.idle": "2023-08-23T18:44:04.484372Z",
     "shell.execute_reply": "2023-08-23T18:44:04.483215Z",
     "shell.execute_reply.started": "2023-08-23T18:33:37.111084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "history = model.fit(x_train_added, y_train_added, epochs=10, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T00:25:11.005045Z",
     "iopub.status.busy": "2023-08-17T00:25:11.004678Z",
     "iopub.status.idle": "2023-08-17T00:25:11.65158Z",
     "shell.execute_reply": "2023-08-17T00:25:11.650792Z",
     "shell.execute_reply.started": "2023-08-17T00:25:11.005017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name = \"BilstmCNN\"\n",
    "inputs = tf.keras.Input(shape=img_shape, name=\"img\")\n",
    "\n",
    "reshaped_input = layers.Reshape((1,128,128,3))(inputs)\n",
    "x1 = TimeDistributed(Conv2D(32,(3,3),activation='relu'))(reshaped_input)\n",
    "x1 = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x1)\n",
    "x1 = TimeDistributed(Conv2D(64,(3,3),activation='relu'))(x1)\n",
    "x1 = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x1)\n",
    "x1 = TimeDistributed(Conv2D(64,(3,3),activation='relu'))(x1)\n",
    "x1 = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(x1)\n",
    "x1 = layers.Reshape((196,64))(x1)\n",
    "x1 = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))(x1)\n",
    "x1 = Bidirectional(LSTM(64,dropout=0.3,recurrent_dropout=0.2))(x1)\n",
    "\n",
    "outputs=Dense(1, activation='sigmoid')(x1)\n",
    "model = keras.Model(inputs, outputs, name=Name)\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T00:25:19.205352Z",
     "iopub.status.busy": "2023-08-17T00:25:19.204986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "history = model.fit(x_train_added, y_train_added, epochs=10, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name = \"CNNATLSTM\"\n",
    "inputs = keras.Input(shape=img_shape, name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = BatchNormalization(axis=-1)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "y = block(x,32)\n",
    "y = block(y,64)\n",
    "y = block(y,128)\n",
    "y = Flatten()(y)\n",
    "y = Dense(128, activation=\"LeakyReLU\", kernel_regularizer=regularizers.l2(0.01))(y)\n",
    "y = Dropout(0.25)(y)\n",
    "\n",
    "converted = tf.image.rgb_to_grayscale(inputs)\n",
    "reshaped_input = layers.Reshape((128,128))(converted)\n",
    "bl1 = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))(reshaped_input)\n",
    "bl2 = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))(bl1)\n",
    "atte_layer=attention()(bl2)\n",
    "merge = layers.Concatenate()([y,atte_layer])\n",
    "y = Dense(64, activation='LeakyReLU',kernel_regularizer=regularizers.l2(0.01))(merge)\n",
    "y = Dropout(0.25)(y)\n",
    "outputs=Dense(1, activation='sigmoid')(y)\n",
    "model = keras.Model(inputs, outputs, name=Name)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T18:22:17.197272Z",
     "iopub.status.busy": "2023-09-23T18:22:17.196921Z",
     "iopub.status.idle": "2023-09-23T18:22:18.136525Z",
     "shell.execute_reply": "2023-09-23T18:22:18.135611Z",
     "shell.execute_reply.started": "2023-09-23T18:22:17.197243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='Cnnattentionlstm.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-23T18:26:32.481284Z",
     "iopub.status.busy": "2023-09-23T18:26:32.48093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "history = model.fit(x_train_added, y_train_added, epochs=100, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "history = model.fit(x_train_added, y_train_added, epochs=100, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **And From here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name = \"CNNATLSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:13:35.143366Z",
     "iopub.status.busy": "2023-08-16T22:13:35.143024Z",
     "iopub.status.idle": "2023-08-16T22:13:35.515559Z",
     "shell.execute_reply": "2023-08-16T22:13:35.514479Z",
     "shell.execute_reply.started": "2023-08-16T22:13:35.143338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test,mask_train,mask_test = train_test_split(images,label,masks,train_size=0.8, random_state=7)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-16T22:46:57.565836Z",
     "iopub.status.busy": "2023-08-16T22:46:57.565479Z",
     "iopub.status.idle": "2023-08-16T22:46:57.889162Z",
     "shell.execute_reply": "2023-08-16T22:46:57.886844Z",
     "shell.execute_reply.started": "2023-08-16T22:46:57.565809Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train_added = np.vstack([x_train,x_test[:2000]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:47:22.179592Z",
     "iopub.status.busy": "2023-08-16T22:47:22.179165Z",
     "iopub.status.idle": "2023-08-16T22:47:22.189371Z",
     "shell.execute_reply": "2023-08-16T22:47:22.188484Z",
     "shell.execute_reply.started": "2023-08-16T22:47:22.179558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train_added.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:48:41.210865Z",
     "iopub.status.busy": "2023-08-16T22:48:41.210498Z",
     "iopub.status.idle": "2023-08-16T22:48:41.218148Z",
     "shell.execute_reply": "2023-08-16T22:48:41.217222Z",
     "shell.execute_reply.started": "2023-08-16T22:48:41.210835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train_added.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:48:28.121248Z",
     "iopub.status.busy": "2023-08-16T22:48:28.12075Z",
     "iopub.status.idle": "2023-08-16T22:48:28.131502Z",
     "shell.execute_reply": "2023-08-16T22:48:28.130498Z",
     "shell.execute_reply.started": "2023-08-16T22:48:28.12121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train_added = np.concatenate((y_train,y_test[:2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T22:44:41.51429Z",
     "iopub.status.busy": "2023-08-16T22:44:41.513927Z",
     "iopub.status.idle": "2023-08-16T22:44:41.523008Z",
     "shell.execute_reply": "2023-08-16T22:44:41.521936Z",
     "shell.execute_reply.started": "2023-08-16T22:44:41.514261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T20:55:35.597239Z",
     "iopub.status.busy": "2023-08-04T20:55:35.596818Z",
     "iopub.status.idle": "2023-08-04T20:55:35.607063Z",
     "shell.execute_reply": "2023-08-04T20:55:35.605738Z",
     "shell.execute_reply.started": "2023-08-04T20:55:35.597206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
    "from tensorflow.keras.applications.convnext import ConvNeXtSmall\n",
    "from tensorflow.keras.applications.convnext import ConvNeXtLarge\n",
    "from tensorflow.keras.applications.convnext import ConvNeXtBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T21:04:33.660401Z",
     "iopub.status.busy": "2023-08-04T21:04:33.659946Z",
     "iopub.status.idle": "2023-08-04T21:04:38.325013Z",
     "shell.execute_reply": "2023-08-04T21:04:38.323906Z",
     "shell.execute_reply.started": "2023-08-04T21:04:33.66037Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "classifier = ResNet152V2(\n",
    "            include_top = False,input_shape=img_shape,\n",
    "             weights='imagenet'\n",
    "           )\n",
    "fine_tune_at = 100\n",
    "for layer in classifier.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# uncomment here \n",
    "classifier = EfficientNetB7(\n",
    "            include_top = False,input_shape=img_shape,\n",
    "             weights='imagenet'\n",
    "           )\n",
    "fine_tune_at = 500\n",
    "for layer in classifier.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# uncomment here \n",
    "\n",
    "classifier = VGG19(\n",
    "            include_top = False,input_shape=img_shape,\n",
    "             weights='imagenet'\n",
    "           )\n",
    "\n",
    "fine_tune_at = 20\n",
    "for layer in classifier.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    " \"\"\"\n",
    "classifier = ConvNeXtSmall(\n",
    "            include_top = False,input_shape=img_shape,\n",
    "             weights='imagenet'\n",
    "           )\n",
    "\n",
    "fine_tune_at = 280\n",
    "for layer in classifier.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T21:04:38.327358Z",
     "iopub.status.busy": "2023-08-04T21:04:38.326995Z",
     "iopub.status.idle": "2023-08-04T21:04:40.910511Z",
     "shell.execute_reply": "2023-08-04T21:04:40.909405Z",
     "shell.execute_reply.started": "2023-08-04T21:04:38.32733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Name='ConvNextsmall'\n",
    "model = Sequential()\n",
    "model.add(classifier)\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-04T21:05:00.28572Z",
     "iopub.status.busy": "2023-08-04T21:05:00.284772Z",
     "iopub.status.idle": "2023-08-04T21:28:47.05401Z",
     "shell.execute_reply": "2023-08-04T21:28:47.052935Z",
     "shell.execute_reply.started": "2023-08-04T21:05:00.285674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model.compile (optimizer= keras.optimizers.Adam(),  loss=keras.losses.BinaryCrossentropy() , metrics=['acc',Recall(),Precision(),AUC(),TruePositives(),TrueNegatives(),FalseNegatives(),FalsePositives()])\n",
    "plot_model(model, to_file=Name+'.png',show_shapes= True , show_layer_names=True)\n",
    "\n",
    "checkpoint_filepath = 'checkpoint.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_freq=5000)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_acc', \n",
    "    patience=15, \n",
    "    min_delta=0.001, \n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), batch_size=64,callbacks=[model_checkpoint_callback, early_stopping])\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower left')\n",
    "plt.savefig(Name+'acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(Name+'loss.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model.save(Name+'.h5')\n",
    "\n",
    "pd.DataFrame.from_dict(history.history).to_csv(Name+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:16:13.763551Z",
     "iopub.status.busy": "2023-11-12T14:16:13.763197Z",
     "iopub.status.idle": "2023-11-12T14:16:14.001495Z",
     "shell.execute_reply": "2023-11-12T14:16:14.000135Z",
     "shell.execute_reply.started": "2023-11-12T14:16:13.763525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from time import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow.keras.backend as K\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#############################\n",
    "\n",
    "def layer_finder(k_model, model_arch, pool_input=True):\n",
    "\n",
    "  '''\n",
    "  Returns a list of all of the last layers in each block of the model.\n",
    "\n",
    "    Parameters:\n",
    "      k_model (Keras model): Either a VGG or ResNet\n",
    "      model_arch (str): Either \"VGG\" or \"ResNet\"\n",
    "\n",
    "    Returns:\n",
    "      last_layers (list): A list of all of the last layers in each block of the\n",
    "      model.\n",
    "  '''\n",
    "  \n",
    "  if type(model_arch) != str:\n",
    "    raise TypeError(\"Input argument \\\"model_arch\\\" must be a string that is\\\n",
    "                      either \\\"VGG\\\" or \\\"ResNet\\\".\")\n",
    "\n",
    "  last_layers = []\n",
    "  pool_flag=False\n",
    "  block_end_detected=False\n",
    "  first_layer=True\n",
    "  j=0\n",
    "\n",
    "  if model_arch == \"VGG\":\n",
    " \n",
    "    for layer in k_model.layers:\n",
    "      if type(layer) == tf.keras.layers.MaxPool2D:\n",
    "        last_layers.append(layer.name)\n",
    "\n",
    "  elif model_arch == \"ResNet\":\n",
    "\n",
    "\n",
    "    for i in range(len(k_model.layers)):\n",
    "      if i<j: continue\n",
    "      #print(k_model.layers[i])\n",
    "      if len(k_model.layers[i+1].output.get_shape()) < 4:\n",
    "        # only save a layer if the block before the end was a convolutional block\n",
    "            last_layers.append(k_model.layers[i].name)\n",
    "            break\n",
    "      \n",
    "      if k_model.layers[i+1].output.get_shape()[2]<k_model.layers[i].output.get_shape()[2]-4:\n",
    "          if pool_input==True:\n",
    "              if type(k_model.layers[i]) == tf.keras.layers.InputLayer: continue\n",
    "              if 'ZeroPadding2D' in str(type(k_model.layers[i])):\n",
    "                  if type(k_model.layers[i-1]) == tf.keras.layers.InputLayer: continue\n",
    "                  last_layers.append(k_model.layers[i-1].name)\n",
    "              else:\n",
    "                  last_layers.append(k_model.layers[i].name)\n",
    "          else:\n",
    "              if first_layer:\n",
    "                  j=i+1\n",
    "                  pool_flag=True\n",
    "                  while(pool_flag):\n",
    "                      j += 1\n",
    "                      #print(str(type(k_model.layers[j])))\n",
    "                      if  'Conv2D' in str(type(k_model.layers[j])):\n",
    "                          #print('Here')\n",
    "                          last_layers.append(k_model.layers[j-1].name)\n",
    "                          first_layer=False\n",
    "                          pool_flag=False\n",
    "              else:\n",
    "                  j=i\n",
    "                  pool_flag=True\n",
    "                  while(pool_flag):\n",
    "                      j += 1\n",
    "                      #print(str(type(k_model.layers[j])))\n",
    "                      if 'merge.Add' in str(type(k_model.layers[j])):\n",
    "                          block_end_detected=True\n",
    "                          #print(j)\n",
    "                      elif block_end_detected==True and 'Conv2D' in str(type(k_model.layers[j])):\n",
    "                          #print('Here')\n",
    "                          last_layers.append(k_model.layers[j-1].name)\n",
    "                          block_end_detected=False\n",
    "                          pool_flag=False\n",
    "  else:\n",
    "    \n",
    "    print(\"Input argument \\\"model_arch\\\" must be either \\\"VGG\\\" or \\\"ResNet\\\".\")\n",
    "\n",
    "  return [[lay] for lay in last_layers]\n",
    "  \n",
    "def create_random_mask(h=7, w=7, H=224, W=224, p_1=0.5, resample=Image.BILINEAR):\n",
    "    '''\n",
    "    Generates one random mask utilized in RISE\n",
    "    inputs:\n",
    "        h, w: initial size of binary mask\n",
    "        H, W: final size of the upsampled mask\n",
    "        p_1: probability of actiating pixels in the down-sampled masks.\n",
    "        interp: upsampling technique.\n",
    "    returns:\n",
    "        mask: a smooth mask with the values in range [0,1] with size of HxW.\n",
    "    '''\n",
    "    assert H>h, 'Masks should be resized to higher dimensions.'\n",
    "    assert W>w, 'Masks should be resized to higher dimensions.'\n",
    "    # create random binary hxw mask\n",
    "    mask=np.random.choice([0, 1], size=(h, w), p=[1-p_1, p_1])\n",
    "\n",
    "    # upsample mask to (h+H,w+W)\n",
    "    mask = Image.fromarray(mask*255.)\n",
    "    mask = mask.resize((H + h, W + w), resample=resample)\n",
    "    mask = np.array(mask)\n",
    "\n",
    "    # randomly crop mask to HxW\n",
    "    w_crop = np.random.randint(0,w+1)\n",
    "    h_crop = np.random.randint(0,h+1)\n",
    "    mask = mask[h_crop:H + h_crop, w_crop:W + w_crop]\n",
    "\n",
    "    # normalize between 0 and 1\n",
    "    mask /= np.max(mask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def create_attribution_masks(img, model, layers, class_index, max_mask_num, interp='bilinear'):\n",
    "    '''\n",
    "    Derives feature maps from one, or a couple of layers, and post-processes them\n",
    "    to convert them to attribution masks.\n",
    "\n",
    "    inputs:\n",
    "        img: a 4-D tensor image.\n",
    "        model: the classification model\n",
    "        layers: list of layers to be visualized either individually or mutually.\n",
    "        class_index: the output class according to whom the layer(s) are visualized.\n",
    "        max_mask_num: the threshold \"normalized gradient\" value for sampling attribution masks (\\mu in our paper)\n",
    "        interp: upsampling technique.\n",
    "        For now, 'bilinear' and 'nearest' are supported.\n",
    "    returns:\n",
    "        masks: a set of attribution masks normalized between 0 and 1.\n",
    "    '''\n",
    "    assert interp in ['bilinear', 'nearest'], 'Selected upsampling type undefined or unsupported.'\n",
    "    # Forward pass to get attribution masks.\n",
    "    conv_outputs=[]\n",
    "    for layer in model.layers:\n",
    "        if np.isin(layer.name,layers):\n",
    "            conv_outputs.append(layer.output)\n",
    "    conv_outputs.append(model.output)\n",
    "    feedforward1=keras.models.Model([model.input], [conv_outputs])\n",
    "    with tf.GradientTape() as tape:\n",
    "        ff_results=feedforward1([img])[0]\n",
    "        all_fmap_masks, predictions = ff_results[:-1], ff_results[-1]\n",
    "        loss = predictions[:, class_index]\n",
    "    grads = tape.gradient(loss, all_fmap_masks)\n",
    "    ###\n",
    "    \n",
    "    # upsample and normalize masks.\n",
    "    num_masks=0\n",
    "    masks=[]\n",
    "    for i in range(len(layers)):\n",
    "        tmp_mask = all_fmap_masks[i][0].numpy()\n",
    "        if len(img.shape)==3:\n",
    "            axis=0\n",
    "            size=img.shape[1:]\n",
    "            tmp_mask = np.expand_dims(tmp_mask, axis=1)\n",
    "        elif len(img.shape)==4:\n",
    "            axis=(0,1)\n",
    "            size=img.shape[1:-1]\n",
    "        significance = np.mean(grads[i][0], axis=axis)\n",
    "        #idxs = np.argpartition(significance, -1*max_mask_num)[-1*max_mask_num:]\n",
    "        idxs = np.where(significance>max_mask_num*np.max(significance))[0]\n",
    "        if interp == 'bilinear':\n",
    "            fmap = tf.image.resize(tmp_mask[...,idxs], size, method='bilinear').numpy()\n",
    "        elif interp == 'nearest':\n",
    "            fmap = tf.image.resize(tmp_mask[...,idxs], size, method='nearest').numpy()\n",
    "        else: raise ValueError('You have selected an unsupported interpolation type.')\n",
    "        \n",
    "        num_masks+=fmap.shape[2]\n",
    "        fmap -= np.min(fmap, axis=(0,1))\n",
    "        fmap /= (np.max(fmap, axis=(0,1))+10e-7)\n",
    "        masks.append(fmap) \n",
    "    return masks\n",
    "\n",
    "def visualize_layers(img, model, class_index, masks, H=224, W=224, C=3, batch_size = 128):\n",
    "    '''\n",
    "    Combines attribution masks using the RISE-based framework mentioned in\n",
    "    SISE white paper.\n",
    "    inputs:\n",
    "        img: a 3-D tensor image.\n",
    "        model: the classification model\n",
    "        class_index: the output class according to whom the layer(s) are visualized.\n",
    "        masks: a set of attribution masks normalized between 0 and 1.\n",
    "    returns:\n",
    "        sum_masks: visualization map of the selected layer(s).\n",
    "    This function follows 'create_attribution_masks()'.\n",
    "    '''\n",
    "    # creates perturbed images to probe model.\n",
    "    img = img if len(img.shape)==3 else np.expand_dims(img, axis=1)\n",
    "    X = np.einsum('hwc,hwn->nhwc', img, masks)\n",
    "    # second forward pass to valuate attribution maps\n",
    "    preds_masked = np.empty([0])\n",
    "    if masks.shape[2] <= batch_size :\n",
    "      preds_masked=np.append(preds_masked, model(X, training=False)[:,class_index],axis=0)\n",
    "    else :\n",
    "      for i in range (0, masks.shape[2]-batch_size, batch_size) :\n",
    "        preds_masked=np.append(preds_masked, model(X[i:i+batch_size], training=False)[:,class_index],axis=0)\n",
    "      preds_masked=np.append(preds_masked, model(X[i+batch_size:], training=False)[:,class_index],axis=0)\n",
    "    \n",
    "    # Linear combination of attribution masks.\n",
    "    masks /= (masks.sum(axis=(0,1))+10e-7)\n",
    "    sum_mask = np.einsum('hwn,n->hw', masks, preds_masked)\n",
    "\n",
    "    sum_mask -= np.min(sum_mask)\n",
    "    sum_mask /= np.max(sum_mask)\n",
    "    return sum_mask\n",
    "    \n",
    "def otsu(I, nbins=256, tau=1.5):\n",
    "    '''\n",
    "    Finds the optimum adaptive threshold value for a 2-D image.\n",
    "    inputs:\n",
    "        I: a 2-D image (visualization map/ heat-map/ etc.)\n",
    "        nbins: resolution of histogram. Increasing this parameter yields to more\n",
    "        precise threshold value, achieved in longer time.\n",
    "        tau: bottleneck amplititude\n",
    "        returns: Otsu adaptive threshold value\n",
    "    '''\n",
    "    I = np.round(I*nbins)\n",
    "    #histogram of the image\n",
    "    hist, bins = np.histogram(I.ravel(),nbins,[0,nbins])\n",
    "    #CDF/ mean/ variance terms for multiple values\n",
    "    i = np.arange(nbins)\n",
    "    varsb = np.zeros(nbins)\n",
    "    for j in range(1, nbins):\n",
    "        w0 = np.sum(hist[0:j])\n",
    "        w1 = np.sum(hist[j:nbins])\n",
    "        u0 = np.sum(np.multiply(hist[0:j], i[0:j])) / w0\n",
    "        u1 = np.sum(np.multiply(hist[j:nbins], i[j:nbins])) / w1\n",
    "        varsb[j] = w0 * w1 * (u0-u1) * (u0-u1)\n",
    "    # the threshold value is the one maximizing the variance term.\n",
    "    t = np.argmax(varsb)\n",
    "    #print(t)\n",
    "    k = round(t*tau)\n",
    "    if np.sum(hist[int(k):256]) < .1 * np.sum(hist):\n",
    "        #print('happened')\n",
    "        return t*tau/nbins\n",
    "    else:\n",
    "        return t/nbins\n",
    "\n",
    "def otsu_sigmoid(I, nbins=256, T=100., tau=1.5):\n",
    "    '''\n",
    "        Thresholds the 2-D visualization map softly, combining Otsu's method and\n",
    "        sigmoid function.\n",
    "        inputs:\n",
    "            I: a 2-D image (visualization map/ heat-map/ etc.)\n",
    "            nbins: resolution of histogram. Increasing this parameter yields to more\n",
    "            precise threshold value, achieved in longer time.\n",
    "            T: sigmoid temparature (preferred to be set to high values.)     \n",
    "        returns:\n",
    "            the soft-thresholded heat-map according to the input.\n",
    "    '''\n",
    "    thr=otsu(I, nbins=256, tau=1.5)\n",
    "    return 1/(1 + np.exp(-(I-thr)*T)) \n",
    "\n",
    "def fuse_visualization_maps(exmaps, fusion_type='otsu', T=100.):\n",
    "    '''\n",
    "    Fuses visualization maps to a unique explanation map. Visualization maps should\n",
    "    be given with the correct order (low-level layer to high-level layer)\n",
    "\n",
    "    '''\n",
    "    assert fusion_type in ['simple', 'otsu']\n",
    "    ex=exmaps[0]\n",
    "    if fusion_type=='simple':\n",
    "        for i in range(1, len(exmaps)):\n",
    "            ex += exmaps[i]\n",
    "            ex *= exmaps[i]\n",
    "    elif fusion_type=='otsu':\n",
    "        for i in range(1, len(exmaps)):\n",
    "            ex += exmaps[i]\n",
    "            ex *= otsu_sigmoid(exmaps[i], T=T)\n",
    "    return ex\n",
    "    \n",
    "def SISE(img, model, class_index, layers, grad_thr, interp='bilinear', \n",
    "         fusion_type='otsu', T=100.):\n",
    "\n",
    "    '''\n",
    "    For now, this function supports VGG16, ResNet50, and ResNet101.\n",
    "    img: a 4-D image, or a 3-D array.\n",
    "    model: the classification model\n",
    "    layers: list of layers to be visualized either individually or mutually.\n",
    "    interp: upsampling technique.\n",
    "    Check the supproted upsampling types in function 'create_attribution_masks'.\n",
    "\tgrad_thr: Threshold on the average gradient values to select the most appropriate feature maps.\n",
    "    fusion_type: the fusion technipue for visualization maps:\n",
    "        simple: Using only addition and multiplication blocks.\n",
    "        otsu: Using addition, soft otsu threshold, and multiplication blocks.\n",
    "    auto_layer_finder: if 'True', the layers are automatically selected. Otherwise,\n",
    "        pre-defined layers for the models experimented are used.\n",
    "    pool_input_select: If True, the inputs of pooling layers are detected automatically.\n",
    "        Otherwise,  the outputs of pooling layers are detected automatically.\n",
    "        If 'auto_layer_finder=False', this parameter is ineffective.\n",
    "    '''\n",
    "    masks = create_attribution_masks(img, model, layers, class_index=class_index, max_mask_num = grad_thr, interp=interp)\n",
    "    exmaps=[]\n",
    "    for mask_set in masks:\n",
    "        exmaps.append(visualize_layers(img[0], model, class_index, mask_set))\n",
    "    return fuse_visualization_maps(exmaps, fusion_type=fusion_type, T=T)\n",
    "    \n",
    "    \n",
    "def weighted_fusion(w,exmaps, T=100.):\n",
    "    '''\n",
    "    Objective: weighted fusion using weighted addition, unweighted multiplication, and otsu threshold blocks.\n",
    "    inputs:\n",
    "        w: an array of weight factors of length N-1.\n",
    "        exmaps: a 3-D array of explanation maps of length H x W x N.\n",
    "    parameters:\n",
    "        N: number of visualiation maps received\n",
    "        H x W: size of visualization maps.\n",
    "    outputs:\n",
    "        e_out: fused explanation map.\n",
    "    '''\n",
    "    #w_post=np.maximum(w,0)\n",
    "    w_post=np.clip(a=w, a_min=0, a_max=2)\n",
    "    e23=np.multiply((exmaps[:,:,0]*w_post[0]+exmaps[:,:,1]*(2-w_post[0])),\n",
    "                    otsu_sigmoid(exmaps[:,:,1], T=T))\n",
    "    e234=np.multiply((e23*w_post[1]+exmaps[:,:,2]*(2-w_post[1])),\n",
    "                    otsu_sigmoid(exmaps[:,:,2], T=T))\n",
    "    e2345=np.multiply((e234*w_post[2]+exmaps[:,:,3]*(2-w_post[2])),\n",
    "                    otsu_sigmoid(exmaps[:,:,3], T=T))\n",
    "    e23456=np.multiply((e2345*w_post[3]+exmaps[:,:,4]*(2-w_post[3])),\n",
    "                    otsu_sigmoid(exmaps[:,:,4], T=T))\n",
    "    e_out = e23456\n",
    "    return e_out\n",
    "\n",
    "def grad_cam(input_model, image, layer_name):\n",
    "    cls = np.argmax(input_model.predict(image))\n",
    "    def normalize(x):\n",
    "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.output\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    feedforward1 = keras.models.Model([input_model.input], [conv_output, y_c])\n",
    "    with tf.GradientTape() as tape:\n",
    "        ff_results=feedforward1([image])\n",
    "        all_fmap_masks, predictions = ff_results[0], ff_results[-1]\n",
    "        loss = predictions[:, cls]\n",
    "    grads_val = tape.gradient(loss, all_fmap_masks)\n",
    "    if len(image.shape)==3:\n",
    "        axis=(0, 1)\n",
    "    elif len(image.shape)==4:\n",
    "        axis=(0, 1, 2)\n",
    "    weights = np.mean(grads_val, axis=axis)\n",
    "    cam = np.dot(all_fmap_masks[0], weights)\n",
    "    #print (cam)\n",
    "    H,W= image.shape[1:3]\n",
    "    cam = np.maximum(cam, 0)\n",
    "    #cam = resize(cam, (H, W))\n",
    "    cam = zoom(cam,H/cam.shape[0])\n",
    "    #cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam\n",
    "\t\n",
    "def RISE(img, model, class_index, N_MASKS=8000, H=224, W=224, C=3):\n",
    "    '''\n",
    "\timg: a 3-D input image\n",
    "\tmodel: a trained model\n",
    "\tclass_index; The class of interest\n",
    "\tN_MASKS: The number of random masks to be generated\n",
    "\tH,W,C: The desired dimensions of the random masks\n",
    "\t'''\n",
    "    X = np.zeros(shape=(N_MASKS, H, W, C), dtype=np.float32)\n",
    "    masks = np.zeros((N_MASKS,H,W), dtype=np.float32)\n",
    "    #for i in tqdm(range(N_MASKS)):\n",
    "    for i in range(N_MASKS):\n",
    "        m =create_random_mask(H=H, W=W)\n",
    "        masks[i] = m\n",
    "        x = img.copy()\n",
    "        x[:, :, 0] *= m\n",
    "        x[:, :, 1] *= m\n",
    "        x[:, :, 2] *= m\n",
    "        X[i] = x\n",
    "    preds_masked = model.predict(X, verbose=0)\n",
    "    sum_mask = np.zeros(masks[0].shape, dtype=np.float32)\n",
    "    #print(preds_masked)\n",
    "    # np.einsum???\n",
    "    for i, mask in enumerate(masks):\n",
    "        m = mask * preds_masked[i, class_index]\n",
    "        sum_mask += m\n",
    "\n",
    "    sum_mask -= np.min(sum_mask)\n",
    "    sum_mask /= np.max(sum_mask)\n",
    "    return sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:16:14.003254Z",
     "iopub.status.busy": "2023-11-12T14:16:14.00295Z",
     "iopub.status.idle": "2023-11-12T14:16:25.264665Z",
     "shell.execute_reply": "2023-11-12T14:16:25.263437Z",
     "shell.execute_reply.started": "2023-11-12T14:16:14.00323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install tf-explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:16:26.63037Z",
     "iopub.status.busy": "2023-11-12T14:16:26.627218Z",
     "iopub.status.idle": "2023-11-12T14:16:26.64895Z",
     "shell.execute_reply": "2023-11-12T14:16:26.647439Z",
     "shell.execute_reply.started": "2023-11-12T14:16:26.630325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tf_explain.core.integrated_gradients import IntegratedGradients\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
    "from tf_explain.core.gradients_inputs import  GradientsInputs\n",
    "from tf_explain.core.vanilla_gradients import  VanillaGradients\n",
    "\n",
    "explainerIG = IntegratedGradients()\n",
    "explainerGP =GradCAM()\n",
    "explainerSG =SmoothGrad()\n",
    "explainerOS =OcclusionSensitivity()\n",
    "explainerGI =GradientsInputs()\n",
    "\n",
    "explainerVG =VanillaGradients()\n",
    "# tf_explain.core.activations module\n",
    "# tf_explain.core.grad_cam module\n",
    "# tf_explain.core.gradients_inputs module\n",
    "# tf_explain.core.integrated_gradients module\n",
    "# tf_explain.core.occlusion_sensitivity module\n",
    "# tf_explain.core.smoothgrad module\n",
    "# tf_explain.core.vanilla_gradients module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:31:59.355335Z",
     "iopub.status.busy": "2023-11-12T14:31:59.355014Z",
     "iopub.status.idle": "2023-11-12T14:31:59.373799Z",
     "shell.execute_reply": "2023-11-12T14:31:59.372799Z",
     "shell.execute_reply.started": "2023-11-12T14:31:59.35531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dispheatmaps(model,image,label,mask_img,index):\n",
    "    img = image.squeeze()\n",
    "    mask = mask_img.squeeze()\n",
    "    explanation_map_GradCAM = abs(grad_cam(model, np.expand_dims(image, axis=0), 'conv2d')).astype('float32')\n",
    "    explanation_map_GradCAM -= explanation_map_GradCAM.min()\n",
    "    if explanation_map_GradCAM.max()!= 0: \n",
    "        explanation_map_GradCAM /= explanation_map_GradCAM.max()+10e-30\n",
    "\n",
    "    explanation_map_IntGrad = explainerIG.explain((np.array([image]), None), model, label).astype('float32')\n",
    "    explanation_map_IntGrad -= explanation_map_IntGrad.min()\n",
    "    explanation_map_IntGrad /= explanation_map_IntGrad.max()+10e-30\n",
    "\n",
    "    explanation_map_GP = explainerGP.explain((np.array([image]), None), model, label, layer_name=\"conv2d_20\").astype('float32')\n",
    "    explanation_map_GP -= explanation_map_GP.min()\n",
    "    explanation_map_GP /= explanation_map_GP.max()+10e-30\n",
    "    \n",
    "    explanation_map_OS = explainerOS.explain((np.array([image]), None), model, label,patch_size=15).astype('float32')\n",
    "    explanation_map_OS -= explanation_map_OS.min()\n",
    "    explanation_map_OS /= explanation_map_OS.max()+10e-30\n",
    "    \n",
    "    explanation_map_SG = abs(grad_cam(model, np.expand_dims(image, axis=0), 'conv2d_14')).astype('float32')\n",
    "    explanation_map_SG -= explanation_map_SG.min()\n",
    "    explanation_map_SG /= explanation_map_SG.max()+10e-30\n",
    "\n",
    "    explanation_map_GI = explainerGI.explain((np.array([image]), None), model, label).astype('float32')\n",
    "    explanation_map_GI -= explanation_map_GI.min()\n",
    "    explanation_map_GI /= explanation_map_GI.max()+10e-30\n",
    "    \n",
    "    explanation_map_VG = explainerVG.explain((np.array([image]), None), model, label).astype('float32')\n",
    "    explanation_map_VG -= explanation_map_VG.min()\n",
    "    explanation_map_VG /= explanation_map_VG.max()+10e-30\n",
    "    \n",
    "    nn = 9\n",
    "    fig = plt.figure(figsize=(25,10))\n",
    "    a = fig.add_subplot(1, nn, 1)\n",
    "    plt.imshow(img)\n",
    "    a.set_title(\"original\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 2)\n",
    "    plt.imshow(mask)\n",
    "    a.set_title(\"Segmentation\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 9)\n",
    "    plt.imshow(explanation_map_GradCAM,cmap='plasma', interpolation='nearest')\n",
    "    a.set_title(\"GradCAM\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 3)\n",
    "    plt.imshow(explanation_map_IntGrad,cmap='plasma', interpolation='nearest')\n",
    "    a.set_title(\"IntGrad\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 4)\n",
    "    plt.imshow(explanation_map_VG,cmap='plasma', interpolation='kaiser')\n",
    "    a.set_title(\"ScoreCAM\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 5)\n",
    "    plt.imshow(explanation_map_GP,cmap='plasma', interpolation='nearest')\n",
    "    a.set_title(\"GradCAM plus\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "    a = fig.add_subplot(1, nn, 6)\n",
    "    plt.imshow(explanation_map_OS,cmap='plasma', interpolation='nearest')\n",
    "    a.set_title(\"OcclusionSensitivity\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 7)\n",
    "    plt.imshow(explanation_map_SG,cmap='plasma', interpolation='nearest')\n",
    "    a.set_title(\"SmoothGrad\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    a = fig.add_subplot(1, nn, 8)\n",
    "    plt.imshow(explanation_map_GI,cmap='plasma', interpolation='none')\n",
    "    a.set_title(\"GradientsInputs\",fontsize=10)\n",
    "    plt.axis('off')\n",
    "    #plt.savefig(\"NovXAI\"+str(index)+'.png')\n",
    "    plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:16:25.267251Z",
     "iopub.status.busy": "2023-11-12T14:16:25.266886Z",
     "iopub.status.idle": "2023-11-12T14:16:26.624327Z",
     "shell.execute_reply": "2023-11-12T14:16:26.623201Z",
     "shell.execute_reply.started": "2023-11-12T14:16:25.267223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = '/kaggle/input/pretrained-model/CnnRegulized_BNLayer.h5'\n",
    "model= keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:32:04.917124Z",
     "iopub.status.busy": "2023-11-12T14:32:04.916706Z",
     "iopub.status.idle": "2023-11-12T14:33:01.135182Z",
     "shell.execute_reply": "2023-11-12T14:33:01.134082Z",
     "shell.execute_reply.started": "2023-11-12T14:32:04.917094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "index = 1014\n",
    "#x_test,y_test \n",
    "prediction=model.predict(x_test)\n",
    "print('True label: '+ str(y_test[index]))\n",
    "print('Predicted_label: '+ str(prediction[index]))\n",
    "print('Confidence score for the correct label: '+str(prediction[index][np.argmax(y_test[index])]))\n",
    "\n",
    "\n",
    "#dispheatmaps(model,x_test[index],np.argmax(prediction[index]),mask_test[index])\n",
    "for i in range(5):\n",
    "    print(i+index)\n",
    "    dispheatmaps(model,x_test[index+i],np.argmax(y_test[index+i]),mask_test[index+i],index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img', 'conv2d', 'max_pooling2d', 'batch_normalization', 'dropout', 'conv2d_2', 'conv2d_3', 'conv2d_1', 'conv2d_4', 'batch_normalization_1', 'batch_normalization_2', 'conv2d_6', 'dropout_1', 'dropout_2', 'batch_normalization_3', 'concatenate', 'conv2d_7', 'max_pooling2d_1', 'conv2d_9', 'conv2d_10', 'conv2d_8', 'conv2d_11', 'batch_normalization_4', 'batch_normalization_5', 'conv2d_13', 'dropout_3', 'dropout_4', 'batch_normalization_6', 'concatenate_1', 'conv2d_14', 'max_pooling2d_2', 'conv2d_16', 'conv2d_17', 'conv2d_15', 'conv2d_18', 'batch_normalization_7', 'batch_normalization_8', 'conv2d_20', 'dropout_5', 'dropout_6', 'batch_normalization_9', 'concatenate_2', 'conv2d_21', 'max_pooling2d_3', 'flatten', 'dense', 'dropout_7', 'dense_1', 'dropout_8', 'dense_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T15:02:39.86511Z",
     "iopub.status.busy": "2023-11-12T15:02:39.864298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for index in range (2000,y_test.shape[0],1):\n",
    "    if(y_test[index]==1):\n",
    "        dispheatmaps(model,x_test[index],np.argmax(y_test[index]),mask_test[index],index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T20:39:34.548208Z",
     "iopub.status.busy": "2023-08-16T20:39:34.547546Z",
     "iopub.status.idle": "2023-08-16T20:39:34.892496Z",
     "shell.execute_reply": "2023-08-16T20:39:34.891462Z",
     "shell.execute_reply.started": "2023-08-16T20:39:34.548171Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dispheatmaps(model,image,label,mask_img):\n",
    "    i=0\n",
    "    for im,mask,leb in zip(image,mask_img,label):\n",
    "        img = im.squeeze()\n",
    "        maski = mask.squeeze()\n",
    "        explanation_map_GradCAM = grad_cam(model, np.expand_dims(img, axis=0), 'conv2d_18')\n",
    "        explanation_map_GradCAM -= explanation_map_GradCAM.min()\n",
    "        explanation_map_GradCAM /= explanation_map_GradCAM.max()+10e-30\n",
    "\n",
    "#         explanation_map_IntGrad = explainerIG.explain((np.array([image]), None), model, label).astype('float32')\n",
    "#         explanation_map_IntGrad -= explanation_map_IntGrad.min()\n",
    "#         explanation_map_IntGrad /= explanation_map_IntGrad.max()+10e-30\n",
    "\n",
    "        explanation_map_GradCAM2 = grad_cam(model, np.expand_dims(image, axis=0), 'conv2d_20')\n",
    "        explanation_map_GradCAM2 -= explanation_map_GradCAM2.min()\n",
    "        explanation_map_GradCAM2 /= explanation_map_GradCAM2.max()+10e-30\n",
    "\n",
    "        explanation_map_GradCAM3 = grad_cam(model, np.expand_dims(image, axis=0), 'conv2d_21')\n",
    "        explanation_map_GradCAM3 -= explanation_map_GradCAM3.min()\n",
    "        explanation_map_GradCAM3 /= explanation_map_GradCAM3.max()+10e-30\n",
    "        \n",
    "        explanation_map_GradCAM4 = grad_cam(model, np.expand_dims(image, axis=0), 'dense_1')\n",
    "        explanation_map_GradCAM4 -= explanation_map_GradCAM4.min()\n",
    "        explanation_map_GradCAM4 /= explanation_map_GradCAM4.max()+10e-30\n",
    "\n",
    "        nn = 7\n",
    "        i=i+1\n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        a = fig.add_subplot(i, nn, 1)\n",
    "        plt.imshow(img)\n",
    "        a.set_title(\"original\",fontsize=10)\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "        a = fig.add_subplot(i, nn, 2)\n",
    "        plt.imshow(explanation_map_GradCAM,cmap='gray', interpolation='nearest')\n",
    "        a.set_title(\"gradCAM\",fontsize=10)\n",
    "        plt.axis('off')\n",
    "\n",
    "#         a = fig.add_subplot(i, nn, 3)\n",
    "#         plt.imshow(explanation_map_IntGrad,cmap='gray', interpolation='nearest')\n",
    "#         a.set_title(\"IntGrad\",fontsize=10)\n",
    "#         plt.axis('off')\n",
    "\n",
    "        a = fig.add_subplot(i, nn, 4)\n",
    "        plt.imshow(explanation_map_GradCAM2,cmap='gray', interpolation='nearest')\n",
    "        a.set_title(\"gradCAM\",fontsize=10)\n",
    "        plt.axis('off')\n",
    "\n",
    "        a = fig.add_subplot(i, nn, 5)\n",
    "        plt.imshow(explanation_map_GradCAM3,cmap='gray', interpolation='nearest')\n",
    "        a.set_title(\"gradCAM\",fontsize=10)\n",
    "        plt.axis('off')\n",
    "\n",
    "        a = fig.add_subplot(i, nn, 6)\n",
    "        plt.imshow(explanation_map_GradCAM4,cmap='gray', interpolation='nearest')\n",
    "        a.set_title(\"gradCAM\",fontsize=10)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        a = fig.add_subplot(1, nn, 7)\n",
    "        plt.imshow(mask)\n",
    "        a.set_title(\"Segmentation\",fontsize=10)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:05:23.669271Z",
     "iopub.status.busy": "2023-11-04T13:05:23.668387Z",
     "iopub.status.idle": "2023-11-04T13:05:35.337791Z",
     "shell.execute_reply": "2023-11-04T13:05:35.336332Z",
     "shell.execute_reply.started": "2023-11-04T13:05:23.669241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tf-keras-vis tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T15:09:24.063382Z",
     "iopub.status.busy": "2023-11-04T15:09:24.062997Z",
     "iopub.status.idle": "2023-11-04T15:09:24.808102Z",
     "shell.execute_reply": "2023-11-04T15:09:24.806809Z",
     "shell.execute_reply.started": "2023-11-04T15:09:24.063349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "# Create Gradcam object\n",
    "score = CategoricalScore(to_categorical(y_test).tolist())\n",
    "gradcam = Gradcam(model,\n",
    "                  model_modifier=ReplaceToLinear(),\n",
    "                  clone=True)\n",
    "\n",
    "# Generate heatmap with GradCAM\n",
    "cam = gradcam(score,\n",
    "              x_test,\n",
    "              penultimate_layer=-1)\n",
    "\n",
    "## Since v0.6.0, calling `normalize()` is NOT necessary.\n",
    "# cam = normalize(cam)\n",
    "\n",
    "# Render\n",
    "f, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "for i, title in enumerate(image_titles):\n",
    "    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "    ax[i].set_title(title, fontsize=16)\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T15:09:04.941756Z",
     "iopub.status.busy": "2023-11-04T15:09:04.941371Z",
     "iopub.status.idle": "2023-11-04T15:09:04.949377Z",
     "shell.execute_reply": "2023-11-04T15:09:04.948217Z",
     "shell.execute_reply.started": "2023-11-04T15:09:04.941724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "to_categorical(y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T13:10:37.094881Z",
     "iopub.status.busy": "2023-11-04T13:10:37.09449Z",
     "iopub.status.idle": "2023-11-04T13:10:37.101134Z",
     "shell.execute_reply": "2023-11-04T13:10:37.100294Z",
     "shell.execute_reply.started": "2023-11-04T13:10:37.094852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T20:33:40.603118Z",
     "iopub.status.busy": "2023-08-16T20:33:40.602719Z",
     "iopub.status.idle": "2023-08-16T20:33:40.620459Z",
     "shell.execute_reply": "2023-08-16T20:33:40.619406Z",
     "shell.execute_reply.started": "2023-08-16T20:33:40.603088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range (y_test.shape[0]):\n",
    "    if y_test[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-16T20:49:04.521404Z",
     "iopub.status.busy": "2023-08-16T20:49:04.520729Z",
     "iopub.status.idle": "2023-08-16T20:49:04.886574Z",
     "shell.execute_reply": "2023-08-16T20:49:04.884466Z",
     "shell.execute_reply.started": "2023-08-16T20:49:04.52137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "newdata = RISE(x_test2[index], model, y_test[index], N_MASKS=800, H=128, W=128, C=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:58:01.561338Z",
     "iopub.status.busy": "2023-08-17T11:58:01.560947Z",
     "iopub.status.idle": "2023-08-17T11:58:01.591508Z",
     "shell.execute_reply": "2023-08-17T11:58:01.590385Z",
     "shell.execute_reply.started": "2023-08-17T11:58:01.561307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_test2 = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T12:35:07.333217Z",
     "iopub.status.busy": "2023-11-12T12:35:07.332542Z",
     "iopub.status.idle": "2023-11-12T12:35:21.228097Z",
     "shell.execute_reply": "2023-11-12T12:35:21.226036Z",
     "shell.execute_reply.started": "2023-11-12T12:35:07.333177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T12:35:25.846643Z",
     "iopub.status.busy": "2023-11-12T12:35:25.846137Z",
     "iopub.status.idle": "2023-11-12T12:37:42.053386Z",
     "shell.execute_reply": "2023-11-12T12:37:42.051787Z",
     "shell.execute_reply.started": "2023-11-12T12:35:25.846601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "test_images = x_test[500:510]\n",
    "e = shap.DeepExplainer(model, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-12T12:37:42.05936Z",
     "iopub.status.busy": "2023-11-12T12:37:42.056147Z",
     "iopub.status.idle": "2023-11-12T12:37:45.815044Z",
     "shell.execute_reply": "2023-11-12T12:37:45.813632Z",
     "shell.execute_reply.started": "2023-11-12T12:37:42.059316Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "shap_values = e.shap_values(test_images)\n",
    "shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values]\n",
    "test_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)\n",
    "\n",
    "shap.image_plot(shap_numpy, -test_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:58:24.32608Z",
     "iopub.status.busy": "2023-08-17T11:58:24.325705Z",
     "iopub.status.idle": "2023-08-17T11:58:24.362491Z",
     "shell.execute_reply": "2023-08-17T11:58:24.36132Z",
     "shell.execute_reply.started": "2023-08-17T11:58:24.326048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "https://github.com/lucasdavid/keras-explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T12:45:49.206154Z",
     "iopub.status.busy": "2023-11-04T12:45:49.205796Z",
     "iopub.status.idle": "2023-11-04T12:46:35.2407Z",
     "shell.execute_reply": "2023-11-04T12:46:35.239688Z",
     "shell.execute_reply.started": "2023-11-04T12:45:49.206119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/lucasdavid/keras-explainable.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T12:38:53.771192Z",
     "iopub.status.busy": "2023-11-12T12:38:53.770702Z",
     "iopub.status.idle": "2023-11-12T12:38:54.812192Z",
     "shell.execute_reply": "2023-11-12T12:38:54.81044Z",
     "shell.execute_reply.started": "2023-11-12T12:38:53.771154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# since we have two inputs we pass a list of inputs to the explainer\n",
    "#here X can be X_test or X_train \n",
    "explainer = shap.GradientExplainer(model, test_images)\n",
    "\n",
    "# we explain the model's predictions on the first three samples of the test set\n",
    "#here X should be less than\n",
    "shap_values = explainer.shap_values(test_images)\n",
    "\n",
    "val= np.array(shap_values[0])\n",
    "valmx=val.max()\n",
    "val= val/valmx\n",
    "\n",
    "shap.image_plot(val,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tf_explain.core.activations import ExtractActivations\n",
    "\n",
    "target_layers = [\n",
    "    'conv2d_21'\n",
    "] \n",
    "image_exp= x_test[1000].squeeze()\n",
    "data = (np.array([image_exp]), None)\n",
    "\n",
    "explainer = ExtractActivations()\n",
    "# Compute Activations of layer activation_1\n",
    "grid = explainer.explain(data, model, target_layers)\n",
    "grid = grid/grid.max()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(grid, cmap='plasma')\n",
    "#plt.savefig(\"Activation_Layer5D7\"+'.png')\n",
    "plt.show()\n",
    "#explainer.save(grid, \".\", \"activations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ", 'conv2d_2', 'conv2d_3', 'conv2d_1', 'conv2d_4', 'conv2d_6', 'conv2d_7', 'conv2d_9', 'conv2d_10',\n",
    "    'conv2d_8', 'conv2d_11', 'conv2d_13',\n",
    "    'conv2d_14',  'conv2d_16', 'conv2d_17', 'conv2d_15', 'conv2d_18',\n",
    "   'conv2d_20', 'conv2d_21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-04T15:31:18.862399Z",
     "iopub.status.busy": "2023-11-04T15:31:18.86153Z",
     "iopub.status.idle": "2023-11-04T15:31:18.868164Z",
     "shell.execute_reply": "2023-11-04T15:31:18.867203Z",
     "shell.execute_reply.started": "2023-11-04T15:31:18.862366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T15:02:20.458921Z",
     "iopub.status.busy": "2023-11-12T15:02:20.457654Z",
     "iopub.status.idle": "2023-11-12T15:02:20.599398Z",
     "shell.execute_reply": "2023-11-12T15:02:20.598Z",
     "shell.execute_reply.started": "2023-11-12T15:02:20.458878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **XAI comparision ekhan Theke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:37:14.346964Z",
     "iopub.status.busy": "2024-03-14T21:37:14.345969Z",
     "iopub.status.idle": "2024-03-14T21:37:14.353689Z",
     "shell.execute_reply": "2024-03-14T21:37:14.352514Z",
     "shell.execute_reply.started": "2024-03-14T21:37:14.346913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_results =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:36:26.936988Z",
     "iopub.status.busy": "2024-03-14T21:36:26.936543Z",
     "iopub.status.idle": "2024-03-14T21:36:28.651634Z",
     "shell.execute_reply": "2024-03-14T21:36:28.650408Z",
     "shell.execute_reply.started": "2024-03-14T21:36:26.936957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Function to detect segments in the projected histogram of an image\n",
    "def detect_segments(projection, threshold=250, min_gap=5):\n",
    "    # Identify where the intensity in the projection is below the threshold (non-white areas)\n",
    "    non_white_areas = np.where(projection < threshold)[0]\n",
    "\n",
    "    if non_white_areas.size == 0:\n",
    "        return []\n",
    "\n",
    "    # Find the breaks in the non_white_areas to identify separate segments\n",
    "    breaks = np.where(np.diff(non_white_areas) > min_gap)[0]\n",
    "    segments = np.split(non_white_areas, breaks+1)\n",
    "\n",
    "    # Identify the start and end of each segment\n",
    "    segments = [(segment[0], segment[-1]) for segment in segments]\n",
    "    return segments\n",
    "\n",
    "# Segment the image using the above function\n",
    "def segment_image(image, white_threshold=250, min_consecutive_white=5):\n",
    "    # Convert to grayscale for easier analysis\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Project the pixel values onto the horizontal and vertical axes\n",
    "    horizontal_projection = gray_image.min(axis=0)\n",
    "    vertical_projection = gray_image.min(axis=1)\n",
    "\n",
    "    # Detect segments in the horizontal and vertical projections\n",
    "    horizontal_segments = detect_segments(horizontal_projection, white_threshold, min_consecutive_white)\n",
    "    vertical_segments = detect_segments(vertical_projection, white_threshold, min_consecutive_white)\n",
    "\n",
    "    # For each horizontal segment, find the matching vertical segment to segment the image\n",
    "    segmented_images = []\n",
    "    for h_start, h_end in horizontal_segments:\n",
    "        for v_start, v_end in vertical_segments:\n",
    "            segment = image[v_start:v_end+1, h_start:h_end+1]\n",
    "            segmented_images.append(segment)\n",
    "\n",
    "    return segmented_images\n",
    "\n",
    "# Apply the segmentation\n",
    "im_path = '/kaggle/working/XAI3107.png'\n",
    "composite_image = cv2.imread(im_path, cv2.IMREAD_COLOR)\n",
    "segmented_images = segment_image(composite_image)\n",
    "\n",
    "# Check how many images were detected and show them\n",
    "print(f\"Number of images detected: {len(segmented_images)}\")\n",
    "\n",
    "# Display the segmented images\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, seg_img in enumerate(segmented_images):\n",
    "    plt.subplot(1, len(segmented_images), i+1)\n",
    "    plt.imshow(cv2.cvtColor(seg_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Image {i+1}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:36:31.877157Z",
     "iopub.status.busy": "2024-03-14T21:36:31.87651Z",
     "iopub.status.idle": "2024-03-14T21:36:31.883978Z",
     "shell.execute_reply": "2024-03-14T21:36:31.882995Z",
     "shell.execute_reply.started": "2024-03-14T21:36:31.877109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_ids =[ 15,5,7,9,11,13,15,17]\n",
    "images =[]\n",
    "for i in image_ids:\n",
    "    seg_img = segmented_images [i]\n",
    "    seg_img = cv2.cvtColor(seg_img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(seg_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:37:00.577003Z",
     "iopub.status.busy": "2024-03-14T21:37:00.576583Z",
     "iopub.status.idle": "2024-03-14T21:37:03.507542Z",
     "shell.execute_reply": "2024-03-14T21:37:03.506323Z",
     "shell.execute_reply.started": "2024-03-14T21:37:00.576968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Function to calculate the cumulative distribution function (CDF)\n",
    "def calculate_cdf(histogram):\n",
    "    cdf = histogram.cumsum()\n",
    "    cdf_normalized = cdf / cdf.max()\n",
    "    return cdf_normalized\n",
    "\n",
    "# Function for histogram matching\n",
    "def match_histograms(source_image, reference_image):\n",
    "    matched_image = np.zeros_like(source_image)\n",
    "    for channel in range(3):\n",
    "        source_hist, _ = np.histogram(source_image[:, :, channel].ravel(), 256, [0, 256])\n",
    "        reference_hist, _ = np.histogram(reference_image[:, :, channel].ravel(), 256, [0, 256])\n",
    "        source_cdf = calculate_cdf(source_hist)\n",
    "        reference_cdf = calculate_cdf(reference_hist)\n",
    "        lookup_table = np.searchsorted(reference_cdf, source_cdf)\n",
    "        matched_image[:, :, channel] = lookup_table[source_image[:, :, channel]]\n",
    "    return matched_image\n",
    "\n",
    "# Read the images and store them in a list\n",
    "#image_file_paths = ['/kaggle/working/XAI3017.png', '/kaggle/working/XAI3006.png', '/kaggle/working/XAI3038.png', '/kaggle/working/XAI3093.png', \n",
    "#                    '/kaggle/working/XAI3098.png', '/kaggle/working/XAI3078.png', '/kaggle/working/XAI3029.png']\n",
    "#images = [cv2.imread(file) for file in image_file_paths]\n",
    "\n",
    "# Define the target histogram (using the first image as a reference)\n",
    "target_image = images[0]\n",
    "\n",
    "# Step 4: Apply histogram matching, adjust brightness, and match black/white levels\n",
    "matched_images = []\n",
    "\n",
    "for img in images:\n",
    "    # Histogram matching\n",
    "    matched = match_histograms(img, target_image)\n",
    "\n",
    "    # Adjust brightness and match black and white levels\n",
    "    min_val, max_val = matched.min(), matched.max()\n",
    "    scale = 255 / (max_val - min_val)\n",
    "    adjusted = np.clip((matched - min_val) * scale, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    matched_images.append(adjusted)\n",
    "\n",
    "# Plot the matched images in a grid\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, image in enumerate(matched_images, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f'Image {i}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Convert each matched image to a weighted grayscale\n",
    "grayscale_images = [cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in matched_images]\n",
    "\n",
    "# Plot the grayscale images in a grid\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, image in enumerate(grayscale_images, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f'Grayscale Image {i}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Apply dynamic thresholding to convert grayscale images to black and white format\n",
    "bw_images = []\n",
    "\n",
    "for i, gray_img in enumerate(grayscale_images):\n",
    "    # Otsu's thresholding\n",
    "    _, bw = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    bw_images.append(bw)\n",
    "    # Save each image\n",
    "    cv2.imwrite(f'bw_image{i}.png', bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:36:42.409323Z",
     "iopub.status.busy": "2024-03-14T21:36:42.408888Z",
     "iopub.status.idle": "2024-03-14T21:36:42.459269Z",
     "shell.execute_reply": "2024-03-14T21:36:42.457472Z",
     "shell.execute_reply.started": "2024-03-14T21:36:42.409284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from skimage.metrics import adapted_rand_error as ARE\n",
    "from skimage.metrics import hausdorff_distance as HD\n",
    "from skimage.metrics import mean_squared_error as MSE\n",
    "from skimage.metrics import normalized_root_mse as Nrmse\n",
    "from skimage.metrics import normalized_mutual_information as NMI\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import variation_of_information as VOI\n",
    "smooth=1.0\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    sum_ = np.sum(y_true + y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac\n",
    "\n",
    "result= [['PSNR', 'IOU', 'DC', 'MSE','NRMSE','NMI']]\n",
    "pred_mask_test = np.array(cv2.cvtColor(segmented_images[3], cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "for i in range (len(bw_images)): \n",
    "    mask_test2 = np.array(bw_images[i])\n",
    "    print(mask_test2.shape)\n",
    "    print(pred_mask_test.shape)\n",
    "    v_PSNR = PSNR(mask_test2,pred_mask_test)\n",
    "    #v_bce_dl = bce_dice_loss(mask_test2,pred_mask_test)\n",
    "    v_dc = dice_coef(mask_test2,pred_mask_test)\n",
    "    v_dl = dice_coef_loss(mask_test2,pred_mask_test)\n",
    "    v_iou = iou(mask_test2,pred_mask_test)\n",
    "    #v_ssim = SSIM(mask_test2,pred_mask_test,data_range=1, channel_axis=3)\n",
    "    #v_are = ARE(mask_test,pred_mask_test)\n",
    "    #v_hd = HD(mask_test,pred_mask_test)\n",
    "    v_mse = MSE(mask_test2,pred_mask_test)\n",
    "    v_nrmse = Nrmse(mask_test2,pred_mask_test)\n",
    "    v_nmi = NMI(mask_test2,pred_mask_test)\n",
    "    #v_voi = VOI(mask_test,pred_mask_test)\n",
    "    result.append([v_PSNR , v_iou ,v_dc ,v_mse,v_nrmse,v_nmi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:37:06.989023Z",
     "iopub.status.busy": "2024-03-14T21:37:06.988166Z",
     "iopub.status.idle": "2024-03-14T21:37:07.023997Z",
     "shell.execute_reply": "2024-03-14T21:37:07.022831Z",
     "shell.execute_reply.started": "2024-03-14T21:37:06.988909Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:37:36.335805Z",
     "iopub.status.busy": "2024-03-14T21:37:36.335256Z",
     "iopub.status.idle": "2024-03-14T21:37:36.341698Z",
     "shell.execute_reply": "2024-03-14T21:37:36.340447Z",
     "shell.execute_reply.started": "2024-03-14T21:37:36.335761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_results.append(np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T21:27:34.836024Z",
     "iopub.status.busy": "2024-03-14T21:27:34.835415Z",
     "iopub.status.idle": "2024-03-14T21:27:34.843661Z",
     "shell.execute_reply": "2024-03-14T21:27:34.842118Z",
     "shell.execute_reply.started": "2024-03-14T21:27:34.835981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "change final result to numpy, avearge in Z axis, thes save as one table \n",
    "Avg_final_results = np.average(axis=0)\n",
    "pd.DataFrame( Avg_final_results),to_csv(\"XAI Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1481536,
     "sourceId": 2448052,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3992072,
     "sourceId": 6950782,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30474,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "lidc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
